{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwt4lEpEdK3L"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaTuSt7LO5eR",
        "outputId": "046ed0d7-fb74-4ca0-f1f1-571a507066c4"
      },
      "source": [
        "import sklearn \n",
        "import os \n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "root = \"/content/drive\"\n",
        "drive.mount(root)\n",
        "os.chdir(\"/content/drive/My Drive/ps_hw_3\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43H0nTg9PZ2T"
      },
      "source": [
        "run = np.loadtxt(\"jogging.csv\", delimiter=\",\")\n",
        "walk = np.loadtxt(\"walk.csv\", delimiter=\",\")\n",
        "stay = np.loadtxt(\"still.csv\", delimiter=\",\")\n",
        "drive = np.loadtxt(\"driving.csv\", delimiter=\",\")\n",
        "climb = np.loadtxt(\"climbing.csv\",delimiter=\",\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdugcHVzQYA_"
      },
      "source": [
        "stay_data = np.hstack((stay, np.ones(stay.shape[0]).reshape((stay.shape[0] ,1)) ))\n",
        "drive_data = np.hstack((drive, np.ones(drive.shape[0]).reshape((drive.shape[0] ,1)) * 2 ))\n",
        "walk_data = np.hstack((walk, np.ones(walk.shape[0]).reshape((walk.shape[0] ,1)) * 3))\n",
        "run_data = np.hstack((run, np.ones(run.shape[0]).reshape((run.shape[0] ,1)) * 4))\n",
        "climb_data = np.hstack((climb, np.ones(climb.shape[0]).reshape((climb.shape[0] ,1)) * 5))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDhac_8YRfoW"
      },
      "source": [
        "stay_data_1 = stay_data[:int(stay_data.shape[0]/30)*30,:]\n",
        "drive_data_1 = drive_data[:int(drive_data.shape[0]/30)*30,:]\n",
        "walk_data_1 = walk_data[:int(walk_data.shape[0]/30)*30,:]\n",
        "run_data_1 = run_data[:int(run_data.shape[0]/30)*30,:]\n",
        "climb_data_1 = climb_data[:int(climb_data.shape[0]/30)*30,:]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6OzN2XgVe9R"
      },
      "source": [
        "A1 = np.zeros((int(stay_data.shape[0]/30),3))\n",
        "A2 = np.zeros((int(drive_data.shape[0]/30),3))\n",
        "A3 = np.zeros((int(walk_data.shape[0]/30),3))\n",
        "A4 = np.zeros((int(run_data.shape[0]/30),3))\n",
        "A5 = np.zeros((int(climb_data.shape[0]/30),3))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfaoJmMHWiRC"
      },
      "source": [
        "for i in range(A1.shape[0]):\n",
        "    A1[i,:] = np.mean(stay_data_1[i * 30 : (i + 1) * 30, :3], axis = 0)\n",
        "for i in range(A2.shape[0]):\n",
        "    A2[i,:] = np.mean(drive_data_1[i * 30 : (i + 1) * 30, :3], axis = 0)\n",
        "for i in range(A3.shape[0]):\n",
        "    A3[i,:] = np.mean(walk_data_1[i * 30 : (i + 1) * 30, :3], axis = 0)\n",
        "for i in range(A4.shape[0]):\n",
        "    A4[i,:] = np.mean(run_data_1[i * 30 : (i + 1) * 30, :3], axis = 0)\n",
        "for i in range(A5.shape[0]):\n",
        "    A5[i,:] = np.mean(climb_data_1[i * 30 : (i + 1) * 30, :3], axis = 0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpffDnZcYW56"
      },
      "source": [
        "B1 = np.hstack((A1.copy(), np.ones(A1.shape[0], dtype = np.int8).reshape(A1.shape[0],1) * 1))\n",
        "B2 = np.hstack((A2.copy(), np.ones(A2.shape[0], dtype = np.int8).reshape(A2.shape[0],1) * 2))\n",
        "B3 = np.hstack((A3.copy(), np.ones(A3.shape[0], dtype = np.int8).reshape(A3.shape[0],1) * 3))\n",
        "B4 = np.hstack((A4.copy(), np.ones(A4.shape[0], dtype = np.int8).reshape(A4.shape[0],1) * 4))\n",
        "B5 = np.hstack((A5.copy(), np.ones(A5.shape[0], dtype = np.int8).reshape(A5.shape[0],1) * 5))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1D-yy8UZb7m"
      },
      "source": [
        "data = np.vstack((B1,B2,B3,B4,B5))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep8CExpuZk0o"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "data_1 = shuffle(data, random_state = 42)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WxiPiLSYFGX",
        "outputId": "350568e4-66f2-407a-e0dc-8353e5572968"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_1[:, :3], data_1[:,3].astype(np.int8), test_size = 0.2, random_state=1024)\n",
        "clf = xgb.XGBClassifier(n_jobs=1)\n",
        "clf.fit(X_train, y_train, early_stopping_rounds=10, eval_metric=\"mlogloss\",\n",
        "        eval_set=[(X_test, y_test)], verbose = False)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DZ9YGGnaK8I"
      },
      "source": [
        "pred_y = clf.predict(X_test)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6E1MRtWbqu2",
        "outputId": "af4cac5e-785e-4cc6-a956-456da1243506"
      },
      "source": [
        "np.sum(pred_y == y_test) / X_test.shape[0]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8435374149659864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgkg_FqGcDvf",
        "outputId": "6573ab22-786c-4bd1-fba5-b255131f6403"
      },
      "source": [
        "xgb_model = xgb.XGBClassifier(n_jobs=1)\n",
        "clf = GridSearchCV(xgb_model,\n",
        "                   {'max_depth': [2, 4, 6],\n",
        "                    'n_estimators': [50, 100, 200]}, verbose=1, n_jobs=1)\n",
        "clf.fit(X_train, y_train)\n",
        "print(clf.best_score_)\n",
        "print(clf.best_params_)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8321544356027115\n",
            "{'max_depth': 4, 'n_estimators': 100}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    5.5s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rIaMwHociYQ",
        "outputId": "037d7511-d92f-4fd5-fa45-4feea0b3b1b3"
      },
      "source": [
        "clf = xgb.XGBClassifier(n_jobs=1, max_depth=4, n_estimators=100)\n",
        "clf.fit(X_train, y_train, early_stopping_rounds=10, eval_metric=\"mlogloss\",\n",
        "        eval_set=[(X_test, y_test)], verbose = False)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A92TqQ8ecpyo"
      },
      "source": [
        "pred_y = clf.predict(X_test)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7y9DjzmdVg_"
      },
      "source": [
        "First one supervised method: Xgboost test-accuracy 0.84"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2qzT10fcrsf",
        "outputId": "048c6e7d-7725-43b4-9aa6-254dac2faf2d"
      },
      "source": [
        "np.sum(pred_y == y_test) / X_test.shape[0]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8435374149659864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUQXhwDJdZOb"
      },
      "source": [
        "Start to try logistic regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeyXZtsmdFQy",
        "outputId": "e08603a6-e441-42c8-e384-7ae7e449265b"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=1024, multi_class = \"multinomial\").fit(X_train, y_train)\n",
        "pred_y = clf.predict(X_test)\n",
        "np.sum(pred_y == y_test) / X_test.shape[0]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6870748299319728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfvSYk6rePpn"
      },
      "source": [
        "The second one supervised method: logistic regression test-accuracy 0.68"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1gukVfYeVbQ"
      },
      "source": [
        "Start to try kernelized svm\n",
        "default is \"rbf\" i.e. gaussian kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iUjiuU-eZdf",
        "outputId": "bf3b6d7c-c4f5-4f77-8172-801e6b1044a6"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(X_train, y_train)\n",
        "pred_y = clf.predict(X_test)\n",
        "np.sum(pred_y == y_test) / X_test.shape[0]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8435374149659864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0F_Oxo1fDu7"
      },
      "source": [
        "Kernel svm give accuary same as xgboost"
      ]
    }
  ]
}